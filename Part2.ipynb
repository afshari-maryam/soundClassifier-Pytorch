{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part2.ipynb","provenance":[],"mount_file_id":"1aQdYB4W6plA6ImAcNG7RSmAoxrqsjYua","authorship_tag":"ABX9TyP2ZINgYQLZ1wrJ8ihpRsv8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Custom Audio Pytorch dataset with Pytorch & torchaudio "],"metadata":{"id":"dEcF7hjz1VPo"}},{"cell_type":"markdown","source":["**USD:**\n","https://urbansounddataset.weebly.com/urbansound8k.html\n","\n"],"metadata":{"id":"pk24t68c1a9Q"}},{"cell_type":"markdown","source":["**torchaudio:**\n","https://pytorch.org/audio/stable/backend.html"],"metadata":{"id":"h-8Meb1H8Juv"}},{"cell_type":"markdown","source":["**torchaudio.transform:**\n","https://pytorch.org/audio/stable/transforms.html"],"metadata":{"id":"miC8F77L4Eq5"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_6hhxYt1HMi","executionInfo":{"status":"ok","timestamp":1647721988060,"user_tz":-210,"elapsed":792221,"user":{"displayName":"Zahra Afshari","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14670526411095207557"}},"outputId":"26e675a7-a70c-4daf-92bd-bd6ef2e13c78"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-19 20:19:55--  https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz\n","Resolving zenodo.org (zenodo.org)... 137.138.76.77\n","Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6023741708 (5.6G) [application/octet-stream]\n","Saving to: ‘urban8k.tgz’\n","\n","urban8k.tgz         100%[===================>]   5.61G  23.2MB/s    in 11m 7s  \n","\n","2022-03-19 20:31:03 (8.61 MB/s) - ‘urban8k.tgz’ saved [6023741708/6023741708]\n","\n"]}],"source":["# Unzip dataset\n","!wget https://zenodo.org/record/1203745/files/UrbanSound8K.tar.gz -O urban8k.tgz\n","!tar -xzf urban8k.tgz\n","!rm urban8k.tgz"]},{"cell_type":"code","source":["!mv \"/content/UrbanSound8K\" \"/content/drive/MyDrive/Afshari/Part2\""],"metadata":{"id":"QL1-GP9S1mBP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import dataset\n","import pandas as pd\n","import torchaudio\n","import os"],"metadata":{"id":"YGrYN3xp1qXY","executionInfo":{"status":"ok","timestamp":1647870792259,"user_tz":-210,"elapsed":7875,"user":{"displayName":"Zahra Afshari","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14670526411095207557"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["class UrbanSoundDataset():\n","\n","  def __init__(self,annotations_file,audio_dir,transformation, target_sample_rate):\n","    self.annotations = pd.read_csv(annotations_file)\n","    self.audio_dir = audio_dir\n","    self.transformation = transformation\n","    self.target_sample_rate = target_sample_rate\n","\n","  def __len__(self):\n","    return len(self.annotations)\n","\n","  #len(usd)\n","  #usd -> urban sound dataset\n","  def __getitem__(self,index):\n","    audio_sample_path = self._get_audio_sample_path(index)\n","    label = self._get_audio_sample_label(index)\n","    signal, sr = torchaudio.load(audio_sample_path)\n","    #signal -> (num_channels,samples) -> (2,16000) -> (1,16000)\n","    signal = self._resample_if_necessary(signal,sr)\n","    signal = self._mix_down_if_necessary(signal)\n","    signal = self.transformation(signal)\n","    return signal,label\n","\n","  def _resample_if_necessary(self,signal,sr):\n","    if sr != self.target_sample_rate:\n","      resampler = torchaudio.transforms.Resample(sr,self.target_sample_rate)\n","      signal = resampler(signal)\n","    return signal\n","\n","  def _mix_down_if_necessary(self,signal):  \n","    if signal.shape[0]>1: #(2,16000)\n","      signal = torch.mean(signal, dim=0, keepdim = True)\n","    return signal\n","\n","\n","  #a_list[] ->a_list.__getitem__(1)\n","\n","  def _get_audio_sample_path(self,index):\n","    fold = f\"fold{self.annotations.iloc[index,5]}\"\n","    path = os.path.join(self.audio_dir,fold,self.annotations.iloc[index,0])\n","    return path\n","  \n","  def _get_audio_sample_label(self,index):\n","    return self.annotations.iloc[index,6]\n","\n","if __name__ == \"__main__\":\n","\n","  ANNOTATIONS_FILE = \"/content/drive/MyDrive/Afshari/Part2/UrbanSound8K/metadata/UrbanSound8K.csv\"\n","  AUDIO_DIR = \"/content/drive/MyDrive/Afshari/Part2/UrbanSound8K/audio\"\n","  SAMPLE_RATE = 16000\n","\n","  mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n","      sample_rate=SAMPLE_RATE,\n","      n_fft= 1024,\n","      hop_length = 512,\n","      n_mels = 64\n","  )\n","  #ms = mel_spectrogram(signal)\n","  usd = UrbanSoundDataset(ANNOTATIONS_FILE, AUDIO_DIR, mel_spectrogram, SAMPLE_RATE)\n","\n","  print(f\"There are {len(usd)} samples in the dataset.\")\n","\n","  signal, label = usd[0]\n","\n","  print(f\"lable = {label}\")\n","  print(f\"lable = {signal.size()}\")\n","\n","  a=1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPhQHIQi1vKH","executionInfo":{"status":"ok","timestamp":1647871618215,"user_tz":-210,"elapsed":481,"user":{"displayName":"Zahra Afshari","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14670526411095207557"}},"outputId":"671f06d2-156c-4ca4-da61-c3040cc0892a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 8732 samples in the dataset.\n","lable = 3\n","lable = torch.Size([1, 64, 10])\n"]}]},{"cell_type":"code","source":[""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXoG_fprK3D_","executionInfo":{"status":"ok","timestamp":1647726790190,"user_tz":-210,"elapsed":2,"user":{"displayName":"Zahra Afshari","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14670526411095207557"}},"outputId":"e57b2296-f55a-468f-c112-129d7488deb5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":6}]}]}